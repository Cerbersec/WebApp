{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\smeet\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\smeet\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from gazpacho import Soup\n",
    "from bs2json import bs2json\n",
    "def getNumbers(str): \n",
    "    array = re.findall(r'[0-9]+', str)\n",
    "    return array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = [\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=1\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=2\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=3\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=4\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=5\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=6\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=7\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=8\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=9\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=10\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=11\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=12\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=13\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=14\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=15\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=16\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=17\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=18\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=19\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=20\"]\n",
    "\n",
    "database = []\n",
    "for element in database_url:\n",
    "    response = requests.get(element)\n",
    "    a = response.json()['results']\n",
    "    database.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID = []\n",
    "shoes_brand = []\n",
    "shoes_gender = []\n",
    "shoes_name = []\n",
    "shoes_year = []\n",
    "shoes_releasedate = []\n",
    "shoes_retailprice = []\n",
    "shoes_shoe = []\n",
    "categorie = []\n",
    "color = []\n",
    "\n",
    "for i in range(len(database)): \n",
    "    lijst = database[i]\n",
    "    for shoe in lijst:\n",
    "        ID = shoe['id']\n",
    "        shoes_ID.append(ID)\n",
    "        brand = shoe['brand']\n",
    "        shoes_brand.append(brand)\n",
    "        gender = shoe['gender']\n",
    "        shoes_gender.append(gender)\n",
    "        name = shoe['name']\n",
    "        shoes_name.append(name)\n",
    "        year = shoe['year']\n",
    "        shoes_year.append(year)\n",
    "        releaseDate = shoe['releaseDate'].split(' ')[0]\n",
    "        shoes_releasedate.append(releaseDate)\n",
    "        retailprice = shoe['retailPrice']\n",
    "        shoes_retailprice.append(retailprice)\n",
    "        kleur = shoe['colorway']\n",
    "        color.append(kleur)\n",
    "        shoe = shoe['shoe']\n",
    "        shoes_shoe.append(shoe)\n",
    "\n",
    "\n",
    "lengte_db = len(database)\n",
    "lengte_lijst = len(lijst)\n",
    "x = lengte_db * lengte_lijst\n",
    "\n",
    "for a in range((x)):\n",
    "    categorie.append(\"shoe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Famaco Eco Wax', 'Famaco Eco Clean 150ml', 'Famaco Eco Protect Spray 150ml', 'Famaco Fama Eco Créme 50ml', 'Famaco Suede Eraser Gomme Net', 'Cleaning Foaming Set Famaco', 'Famaco Crème Délicate Naturel', 'Famaco Eraser Soft Gom', 'Famaco Elegance Leather Shine Sponge', 'Famaco Eco Wax', 'Famaco Eco Clean 150ml', 'Famaco Eco Protect Spray 150ml', 'Famaco Fama Eco Créme 50ml', 'Famaco Suede Eraser Gomme Net', 'Cleaning Foaming Set Famaco', 'Famaco Crème Délicate Naturel', 'Famaco Eraser Soft Gom', 'Famaco Elegance Leather Shine Sponge']\n"
     ]
    }
   ],
   "source": [
    "schoenverzorging = [\"https://www.torfs.be/nl/dames/accessoires/schoenverzorging/?cgid=Dames-Accessoires-Schoenverzorging&sz=24\",\"https://www.torfs.be/nl/heren/accessoires/schoenverzorging/?cgid=Heren-Accessoires-Schoenverzorging&sz=24\"]\n",
    "\n",
    "prijzen_schoenverzorging=[]\n",
    "product_categorie = []\n",
    "brand = []\n",
    "ids = []\n",
    "product_name = []\n",
    "product_gender_schoenverzorging = []\n",
    "kleur = []\n",
    "\n",
    "for a in schoenverzorging:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    productDivs = soup.findAll('div', attrs={'class' : 'pdp-link brand'})\n",
    "    for div in productDivs:\n",
    "        a = (div.find('a')['href'])\n",
    "        a = a.split('nl/')[1]\n",
    "        a = a.split('/')[0]\n",
    "        product_gender_schoenverzorging.append(a)\n",
    "        \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('€','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_schoenverzorging.append(a)\n",
    "        \n",
    "            \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie.append(a)\n",
    "        \n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Schoenverzorging\":\n",
    "            brand.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids.append(a[len(a) - 1])\n",
    "        \n",
    "    \n",
    "\n",
    "    title = soup.findAll('meta',  itemprom=\"analytics\")\n",
    "    for x, i in enumerate(title):\n",
    "        strings = str(title[x])\n",
    "        woord =(strings.split('\"name\":')[1])\n",
    "        woord1 = woord.split(\",\")[0]\n",
    "        woord1 = woord1.lstrip('\" ')\n",
    "        woord1 = woord1.rstrip('\" ')\n",
    "        product_name.append(woord1)\n",
    "        \n",
    "for a in range(len(prijzen_schoenverzorging)):\n",
    "    kleur.append(\"/\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lijsten bij elkaar voegen\n",
    "shoes_ID.extend(ids)\n",
    "shoes_brand.extend(brand)\n",
    "shoes_retailprice.extend(prijzen_schoenverzorging)\n",
    "shoes_shoe.extend(product_name)\n",
    "categorie.extend(product_categorie)\n",
    "shoes_gender.extend(product_gender_schoenverzorging)\n",
    "color.extend(kleur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "zolen = [\"https://www.torfs.be/nl/dames/accessoires/zolen/?cgid=Dames-Accessoires-Zolen&sz=24\",\"https://www.torfs.be/nl/heren/accessoires/zolen/?cgid=Heren-Accessoires-Zolen&sz=24\"]\n",
    "\n",
    "prijzen_zolen=[]\n",
    "product_categorie_zolen = []\n",
    "brand_zolen = []\n",
    "ids_zolen = []\n",
    "product_name_zolen = []\n",
    "product_gender_zolen = []\n",
    "kleur_zolen = []\n",
    "for a in zolen:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    productDivs = soup.findAll('div', attrs={'class' : 'pdp-link brand'})\n",
    "    for div in productDivs:\n",
    "        a = (div.find('a')['href'])\n",
    "        a = a.split('nl/')[1]\n",
    "        a = a.split('/')[0]\n",
    "        product_gender_zolen.append(a)\n",
    "        \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('€','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_zolen.append(a)\n",
    "        \n",
    "            \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_zolen.append(a)\n",
    "        \n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Zolen\":\n",
    "            brand_zolen.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_zolen.append(a[len(a) - 1])\n",
    "        \n",
    "    \n",
    "\n",
    "    title = soup.findAll('meta',  itemprom=\"analytics\")\n",
    "    for x, i in enumerate(title):\n",
    "        strings = str(title[x])\n",
    "        woord =(strings.split('\"name\":')[1])\n",
    "        woord1 = woord.split(\",\")[0]\n",
    "        woord1 = woord1.lstrip('\" ')\n",
    "        woord1 = woord1.rstrip('\" ')\n",
    "        product_name_zolen.append(woord1)\n",
    "        \n",
    "for a in range(len(prijzen_zolen)):\n",
    "    kleur_zolen.append(\"/\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_zolen)\n",
    "shoes_brand.extend(brand_zolen)\n",
    "shoes_retailprice.extend(prijzen_zolen)\n",
    "shoes_shoe.extend(product_name_zolen)\n",
    "categorie.extend(product_categorie_zolen)\n",
    "shoes_gender.extend(product_gender_zolen)\n",
    "color.extend(kleur_zolen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "riemen = [\"https://www.torfs.be/nl/dames/accessoires/riemen/?cgid=Dames-Accessoires-Riemen&sz=24\", \"https://www.torfs.be/nl/heren/accessoires/riemen/?cgid=Heren-Accessoires-Riemen&sz=24\"]\n",
    "\n",
    "\n",
    "prijzen_riemen=[]\n",
    "product_categorie_riemen = []\n",
    "brand_riemen = []\n",
    "ids_riemen = []\n",
    "product_name_riemen = []\n",
    "product_gender_riemen = []\n",
    "kleur_riemen = []\n",
    "            \n",
    "for a in riemen:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('€','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_riemen.append(a)\n",
    "        \n",
    "    productDivs = soup.findAll('div', attrs={'class' : 'pdp-link brand'})\n",
    "    for div in productDivs:\n",
    "        a = (div.find('a')['href'])\n",
    "        a = a.split('nl/')[1]\n",
    "        a = a.split('/')[0]\n",
    "        product_gender_riemen.append(a)\n",
    "\n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_riemen.append(a)\n",
    "\n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Riem\":\n",
    "            brand_riemen.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_riemen.append(a[len(a) - 1])\n",
    "        \n",
    "    \n",
    "\n",
    "    title = soup.findAll('meta',  itemprom=\"analytics\")\n",
    "    for x, i in enumerate(title):\n",
    "        strings = str(title[x])\n",
    "        woord =(strings.split('\"name\":')[1])\n",
    "        woord1 = woord.split(\",\")[0]\n",
    "        woord1 = woord1.lstrip('\" ')\n",
    "        woord1 = woord1.rstrip('\" ')\n",
    "        product_name_riemen.append(woord1)\n",
    "\n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_riemen.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_riemen)\n",
    "shoes_brand.extend(brand_riemen)\n",
    "shoes_retailprice.extend(prijzen_riemen)\n",
    "shoes_shoe.extend(product_name_riemen)\n",
    "categorie.extend(product_categorie_riemen)\n",
    "shoes_gender.extend(product_gender_riemen)\n",
    "color.extend(kleur_riemen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wit ', 'zwart ', 'cognac ', 'bruin ', 'grijs ', 'blauw ', 'bordeaux ', 'brons ', 'goud ', 'zilver ', 'beige ', 'geel ', 'roze ', 'paars ', 'groen ', 'multi ', 'wit ', 'zwart ', 'bruin ', 'grijs ', 'blauw ', 'geel ', 'roze ', 'multi ', 'wit ', 'zwart ', 'cognac ', 'bruin ', 'grijs ', 'blauw ', 'bordeaux ', 'brons ', 'goud ', 'zilver ', 'beige ', 'geel ', 'roze ', 'paars ', 'groen ', 'multi ', 'wit ', 'zwart ', 'bruin ', 'grijs ', 'blauw ', 'geel ', 'roze ', 'multi ']\n"
     ]
    }
   ],
   "source": [
    "sokken = [\"https://www.torfs.be/nl/dames/accessoires/sokken/?cgid=Dames-Accessoires-Sokken&sz=24\", \"https://www.torfs.be/nl/heren/accessoires/sokken/?cgid=Heren-Accessoires-Sokken&sz=24\"]\n",
    "\n",
    "aantal_sokken_vrouwen = int(getNumbers(\"https://www.torfs.be/nl/dames/accessoires/sokken/?cgid=Dames-Accessoires-Sokken&sz=24\")[0])\n",
    "aantal_sokken_mannen = int(getNumbers(\"https://www.torfs.be/nl/heren/accessoires/sokken/?cgid=Heren-Accessoires-Sokken&sz=24\")[0])\n",
    "\n",
    "prijzen_sokken=[]\n",
    "product_categorie_sokken = []\n",
    "brand_sokken = []\n",
    "ids_sokken = []\n",
    "product_name_sokken = []\n",
    "product_gender_sokken = []\n",
    "kleur_sokken = []\n",
    "kleur_sokken_2 = []\n",
    "lijst = []\n",
    "for a in sokken:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('€','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_sokken.append(a)\n",
    "        \n",
    "            \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_sokken.append(a)\n",
    "        \n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Sokken\" or a != \"Sokken\\n\":\n",
    "            brand_sokken.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_sokken.append(a[len(a) - 1])\n",
    "        \n",
    "    \n",
    "    test = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for x, i in enumerate(test):\n",
    "        a = str(test[x])\n",
    "        b = a.split('alt=')[1]\n",
    "        b = b.split(' \" class')[0]\n",
    "        b = b.lstrip('\" ')\n",
    "        b = b.rstrip('\" ')\n",
    "        product_name_sokken.append(b)\n",
    "    \n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_sokken.append(c)\n",
    "        \n",
    "    branding = soup.findAll('div', attrs = {'class' : 'content-asset js-seo-content'})\n",
    "\n",
    "    for row in branding:\n",
    "        a1 = row.find('h2').text\n",
    "        a1 = a1.split(' ')[2]\n",
    "        lijst.append(a1)\n",
    "\n",
    "        \n",
    "for x in range(aantal_sokken_vrouwen):\n",
    "    product_gender_sokken.append(lijst[0])\n",
    "for x in range(aantal_sokken_mannen):\n",
    "    product_gender_sokken.append(lijst[1])\n",
    "\n",
    "kleur_sokken_2 = kleur_sokken + kleur_sokken\n",
    "print(kleur_sokken_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2076\n"
     ]
    }
   ],
   "source": [
    "shoes_ID.extend(ids_sokken)\n",
    "shoes_brand.extend(brand_sokken)\n",
    "shoes_retailprice.extend(prijzen_sokken)\n",
    "shoes_shoe.extend(product_name_sokken)\n",
    "categorie.extend(product_categorie_sokken)\n",
    "shoes_gender.extend(product_gender_sokken)\n",
    "color.extend(kleur_sokken_2)\n",
    "print(len(categorie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2076\n"
     ]
    }
   ],
   "source": [
    "print(len(shoes_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,i in enumerate(shoes_brand):\n",
    "    if i == \"Sokken\" or i == \"Enkelsokken\":\n",
    "        shoes_brand.remove(i)\n",
    "\n",
    "\n",
    "for i in range(len(shoes_ID) - len(shoes_name)):\n",
    "    shoes_name.append(\"Nan\")\n",
    "for i in range(len(shoes_ID) - len(shoes_year)):\n",
    "    shoes_year.append(\"2020\")\n",
    "for i in range(len(shoes_ID) - len(shoes_releasedate)):\n",
    "    shoes_releasedate.append(\"2020-01-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-48c082d12f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;34m'Year'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mshoes_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;34m'ReleaseDate'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mshoes_releasedate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;34m'Product_Category'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mcategorie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m })\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    409\u001b[0m             )\n\u001b[0;32m    410\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         ]\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ID': shoes_ID,\n",
    "    'Brand': shoes_brand,\n",
    "    'Gender': shoes_gender,\n",
    "    'Retail_Price': shoes_retailprice,\n",
    "    'Product': shoes_shoe,\n",
    "    'Name': shoes_name,\n",
    "    'Year': shoes_year,\n",
    "    'ReleaseDate': shoes_releasedate,\n",
    "    'Product_Category' : categorie\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Retail_Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = [df]\n",
    "for dataset in data_cleaner:    \n",
    "    dataset['Retail_Price'].fillna(dataset['Retail_Price'].mean(), inplace = True)\n",
    "    dataset['Retail_Price'] = dataset['Retail_Price'].replace(0, mean)  \n",
    "    \n",
    "    \n",
    "dataset['Retail_Price'] = dataset['Retail_Price'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "Brand               0\n",
       "Gender              0\n",
       "Retail_Price        0\n",
       "Product             0\n",
       "Name                0\n",
       "Year                0\n",
       "ReleaseDate         0\n",
       "Product_Category    0\n",
       "Sales_Price         0\n",
       "Review_ID           0\n",
       "Stock               0\n",
       "Size                0\n",
       "Category_ID         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales_Price'] = df.apply(lambda row: row.Retail_Price + (row.Retail_Price * 0.2), axis = 1)\n",
    "df['Sales_Price'] = df['Sales_Price'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        ID         Brand     Gender  \\\n",
      "0     c624af9c-ce0e-4e4d-b6a3-6e90efe04491        adidas        men   \n",
      "1     d4e38d0c-d7a9-4d35-9988-6d7d8fb0b76f          Puma        men   \n",
      "2     dcfd3490-0f1b-45bf-9a9a-513dac49bef8        Reebok        men   \n",
      "3     ef9dd9ca-b7a7-4f3a-a1a5-58338a24828a        adidas        men   \n",
      "4     fbc8732c-e1d4-42a7-bfc8-52d63a9db52e          Nike  preschool   \n",
      "...                                    ...           ...        ...   \n",
      "2071                                270423        Levi's      heren   \n",
      "2072                                265014        Stance      heren   \n",
      "2073                                255639  Calvin Klein      heren   \n",
      "2074                                255637  Calvin Klein      heren   \n",
      "2075                                255642  Calvin Klein      heren   \n",
      "\n",
      "      Retail_Price                                        Product  \\\n",
      "0           140.00                                adidas Forum Lo   \n",
      "1           190.00                                     Puma Suede   \n",
      "2           130.00                     Reebok Premier Road Modern   \n",
      "3           150.00                               adidas Forum Mid   \n",
      "4            80.00                                 Nike Kybrid S2   \n",
      "...            ...                                            ...   \n",
      "2071          7.99             Levi's Blauwe Enkelsokken - 2 Paar   \n",
      "2072         29.95  Stance Foundation Pack Zwarte Sokken - 3 Paar   \n",
      "2073         15.95            Calvin Klein Zwarte Sokken - 2 Paar   \n",
      "2074         15.95            Calvin Klein Blauwe Sokken - 2 Paar   \n",
      "2075         15.95                     Calvin Klein Blauwe Sokken   \n",
      "\n",
      "                             Name  Year ReleaseDate Product_Category  \\\n",
      "0     Beyonce Ivy Park Core White  2020  2020-10-30             shoe   \n",
      "1      atmos x Three Tides Tattoo  2020  2020-10-30             shoe   \n",
      "2                    Kanghyuk Red  2020  2020-10-30             shoe   \n",
      "3     Beyonce Ivy Park Green Tint  2020  2020-10-30             shoe   \n",
      "4                    Best Of (PS)  2020  2020-10-30             shoe   \n",
      "...                           ...   ...         ...              ...   \n",
      "2071                          Nan  2020  2020-01-01      Enkelsokken   \n",
      "2072                          Nan  2020  2020-01-01           Sokken   \n",
      "2073                          Nan  2020  2020-01-01           Sokken   \n",
      "2074                          Nan  2020  2020-01-01           Sokken   \n",
      "2075                          Nan  2020  2020-01-01           Sokken   \n",
      "\n",
      "      Sales_Price Review_ID  Stock     Size       Category_ID  \n",
      "0          168.00   UMOTMPF     50  38 - 47  S332167850164114  \n",
      "1          228.00   I0GG131    139  38 - 47  S332167850164114  \n",
      "2          156.00   Q37JAN1    115  38 - 47  S332167850164114  \n",
      "3          180.00   S2H03LK     11  38 - 47  S332167850164114  \n",
      "4           96.00   JW31Y5E    138  27 - 30  S332167850164114  \n",
      "...           ...       ...    ...      ...               ...  \n",
      "2071         9.59   9R2USCN     96   1 size  E154548552657254  \n",
      "2072        35.94   5FVV7J6    144   1 size  S154687234121457  \n",
      "2073        19.14   CQPJ9OD    140   1 size  S154687234121457  \n",
      "2074        19.14   ZJ4O8E2     32   1 size  S154687234121457  \n",
      "2075        19.14   01P0S6E    131   1 size  S154687234121457  \n",
      "\n",
      "[2076 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import random \n",
    "\n",
    "  \n",
    "N = 7\n",
    "lengte = len(df['ID']) \n",
    "\n",
    "review_ID = []\n",
    "\n",
    "\n",
    "for i in range(lengte):\n",
    "    res = ''.join(random.choices(string.ascii_uppercase +\n",
    "                             string.digits, k = N)) \n",
    "    review_ID.append(res)\n",
    "\n",
    "\n",
    "\n",
    "df['Review_ID'] = review_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "stock = []\n",
    "for i in range(lengte):\n",
    "    x = randint(10,150)\n",
    "    stock.append(x)\n",
    "\n",
    "\n",
    "df['Stock'] = stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = df['Gender']\n",
    "size = []\n",
    "for count,ele in enumerate(gender):\n",
    "    if ele == \"men\":\n",
    "        size.insert(count, '38 - 47')\n",
    "    elif ele == \"child\":\n",
    "        size.insert(count, '34 - 37')\n",
    "    elif ele == \"infant\":\n",
    "        size.insert(count, '20 - 26')\n",
    "    elif ele == \"preschool\":\n",
    "        size.insert(count, '27 - 30')\n",
    "    elif ele == \"toddler\":\n",
    "        size.insert(count, '31 - 34')\n",
    "    elif ele == \"women\":\n",
    "        size.insert(count, '34 - 45')\n",
    "    else:\n",
    "        size.insert(count, '1 size')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Size'] = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id = []\n",
    "for x,i in enumerate((df['Product_Category'])):\n",
    "    if i == 'shoe':\n",
    "        category_id.append(\"S332167850164114\")\n",
    "    elif i == 'Schoenverzorging':  \n",
    "        category_id.append(\"S332789501641287\")\n",
    "    elif i == 'Zolen'  :\n",
    "        category_id.append(\"Z486824285647812\")\n",
    "    elif i == 'Riem'  :\n",
    "        category_id.append(\"R486154872548563\")\n",
    "    elif i == 'Sokken'  :\n",
    "        category_id.append(\"S154687234121457\") \n",
    "    elif i == 'Enkelsokken' : \n",
    "        category_id.append(\"E154548552657254\")   \n",
    "    else:\n",
    "        category_id.append(\"/\")\n",
    "df['Category_ID'] = category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2076\n"
     ]
    }
   ],
   "source": [
    "df['Color'] = color\n",
    "print(len(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        ID         Brand     Gender  \\\n",
      "0     c624af9c-ce0e-4e4d-b6a3-6e90efe04491        adidas        men   \n",
      "1     d4e38d0c-d7a9-4d35-9988-6d7d8fb0b76f          Puma        men   \n",
      "2     dcfd3490-0f1b-45bf-9a9a-513dac49bef8        Reebok        men   \n",
      "3     ef9dd9ca-b7a7-4f3a-a1a5-58338a24828a        adidas        men   \n",
      "4     fbc8732c-e1d4-42a7-bfc8-52d63a9db52e          Nike  preschool   \n",
      "...                                    ...           ...        ...   \n",
      "2071                                270423        Levi's      heren   \n",
      "2072                                265014        Stance      heren   \n",
      "2073                                255639  Calvin Klein      heren   \n",
      "2074                                255637  Calvin Klein      heren   \n",
      "2075                                255642  Calvin Klein      heren   \n",
      "\n",
      "      Retail_Price                                        Product  \\\n",
      "0           140.00                                adidas Forum Lo   \n",
      "1           190.00                                     Puma Suede   \n",
      "2           130.00                     Reebok Premier Road Modern   \n",
      "3           150.00                               adidas Forum Mid   \n",
      "4            80.00                                 Nike Kybrid S2   \n",
      "...            ...                                            ...   \n",
      "2071          7.99             Levi's Blauwe Enkelsokken - 2 Paar   \n",
      "2072         29.95  Stance Foundation Pack Zwarte Sokken - 3 Paar   \n",
      "2073         15.95            Calvin Klein Zwarte Sokken - 2 Paar   \n",
      "2074         15.95            Calvin Klein Blauwe Sokken - 2 Paar   \n",
      "2075         15.95                     Calvin Klein Blauwe Sokken   \n",
      "\n",
      "                             Name  Year ReleaseDate Product_Category  \\\n",
      "0     Beyonce Ivy Park Core White  2020  2020-10-30             shoe   \n",
      "1      atmos x Three Tides Tattoo  2020  2020-10-30             shoe   \n",
      "2                    Kanghyuk Red  2020  2020-10-30             shoe   \n",
      "3     Beyonce Ivy Park Green Tint  2020  2020-10-30             shoe   \n",
      "4                    Best Of (PS)  2020  2020-10-30             shoe   \n",
      "...                           ...   ...         ...              ...   \n",
      "2071                          Nan  2020  2020-01-01      Enkelsokken   \n",
      "2072                          Nan  2020  2020-01-01           Sokken   \n",
      "2073                          Nan  2020  2020-01-01           Sokken   \n",
      "2074                          Nan  2020  2020-01-01           Sokken   \n",
      "2075                          Nan  2020  2020-01-01           Sokken   \n",
      "\n",
      "      Sales_Price Review_ID  Stock     Size       Category_ID  \\\n",
      "0          168.00   DU2B8YR     77  38 - 47  S332167850164114   \n",
      "1          228.00   6MG3KE2     69  38 - 47  S332167850164114   \n",
      "2          156.00   3YF83GD    105  38 - 47  S332167850164114   \n",
      "3          180.00   8BS5VCD    117  38 - 47  S332167850164114   \n",
      "4           96.00   O91YM0D     90  27 - 30  S332167850164114   \n",
      "...           ...       ...    ...      ...               ...   \n",
      "2071         9.59   L7NWR8F     12   1 size  E154548552657254   \n",
      "2072        35.94   A9WM833     18   1 size  S154687234121457   \n",
      "2073        19.14   O4HEI0M     52   1 size  S154687234121457   \n",
      "2074        19.14   9IEZY4B     69   1 size  S154687234121457   \n",
      "2075        19.14   FIDWMWO    116   1 size  S154687234121457   \n",
      "\n",
      "                                 Color  \n",
      "0     Core White/Clear Brown/Ecru Tint  \n",
      "1                Puma Black/Puma White  \n",
      "2                            White/Red  \n",
      "3                Green Tint/Green Tint  \n",
      "4              Multi-Color/Multi-Color  \n",
      "...                                ...  \n",
      "2071                            grijs   \n",
      "2072                            blauw   \n",
      "2073                             geel   \n",
      "2074                             roze   \n",
      "2075                            multi   \n",
      "\n",
      "[2076 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('product_database.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "360\n",
      "720\n",
      "360\n",
      "360\n",
      "357\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59.95, 95.95, 59.95, 59.95, 49.95, 99.95, 99.95, 89.95, 69.95, 99.95, 89.95, 49.95, 89.95, 99.95, 59.95, 79.95, 39.95, 79.95, 89.95, 79.95, 79.95, 99.95, 99.95, 99.95, 160.0, 69.95, 59.99, 55.95, 59.99, 69.99, 180.0, 69.95, 85.95, 170.0, 79.95, 99.95, 99.95, 160.0, 69.95, 180.0, 120.0, 160.0, 160.0, 160.0, 150.0, 150.0, 69.95, 130.0, 85.95, 160.0, 79.95, 160.0, 160.0, 180.0, 180.0, 160.0, 69.95, 195.0, 79.95, 160.0, 160.0, 75.95, 220.0, 160.0, 205.0, 130.0, 99.95, 150.0, 160.0, 99.95, 160.0, 140.0, 180.0, 120.0, 180.0, 89.95, 245.0, 85.95, 150.0, 120.0, 145.0, 170.0, 89.95, 79.95, 79.95, 89.95, 89.95, 79.95, 79.95, 79.95, 89.95, 79.99, 95.95, 130.0, 180.0, 170.0, 89.95, 160.0, 160.0, 140.0, 99.99, 150.0, 89.95, 95.95, 99.99, 99.95, 110.0, 69.95, 220.0, 220.0, 170.0, 240.0, 99.95, 150.0, 160.0, 180.0, 140.0, 160.0, 140.0, 140.0, 95.95, 95.95, 89.95, 89.95, 89.95, 99.95, 170.0, 99.95, 180.0, 95.95, 170.0, 170.0, 240.0, 89.95, 89.95, 160.0, 89.95, 140.0, 85.95, 95.95, 215.0, 79.95, 99.95, 99.95, 95.95, 95.95, 89.95, 95.95, 79.95, 170.0, 89.99, 85.95, 160.0, 89.95, 120.0, 120.0, 120.0, 110.0, 120.0, 140.0, 59.95, 85.95, 140.0, 89.99, 95.95, 215.0, 55.95, 140.0, 55.95, 59.95, 59.95, 55.95, 49.95, 49.95, 49.95, 65.95, 49.95, 49.95, 55.95, 49.95, 49.95, 55.95, 55.95, 69.95, 49.95, 110.0, 110.0, 65.95, 69.95, 25.95, 25.95, 25.95, 25.95, 39.95, 39.95, 49.95, 49.95, 45.95, 45.95, 45.95, 55.95, 49.95, 35.95, 35.95, 39.95, 29.95, 59.95, 69.95, 95.95, 89.95, 89.95, 89.95, 85.95, 45.95, 45.95, 65.95, 65.95, 69.95, 69.95, 59.95, 69.95, 75.95, 55.95, 49.95, 49.95, 49.95, 49.95, 79.95, 85.95, 79.95, 79.95, 79.95, 69.95, 59.95, 85.95, 69.95, 89.95, 55.95, 54.95, 69.95, 99.95, 75.95, 99.95, 99.95, 65.95, 89.95, 59.95, 69.95, 75.95, 59.95, 75.95, 55.95, 75.95, 75.95, 79.95, 49.95, 35.95, 39.95, 69.95, 69.95, 39.95, 29.95, 79.95, 29.95, 25.95, 25.95, 25.95, 25.95, 25.95, 39.95, 39.95, 75.95, 65.95, 55.95, 59.95, 49.95, 35.95, 69.95, 49.95, 85.95, 85.95, 39.95, 39.95, 29.95, 95.95, 89.95, 99.95, 59.95, 75.95, 69.95, 75.95, 69.95, 75.95, 89.95, 89.95, 79.95, 99.95, 65.95, 45.95, 49.95, 79.95, 79.95, 65.95, 49.95, 65.95, 55.95, 59.95, 79.95, 79.95, 69.95, 65.95, 59.95, 79.95, 79.95, 75.95, 69.95, 65.95, 49.95, 85.95, 85.95, 69.95, 69.95, 95.95, 49.95, 65.95, 95.95, 79.95, 55.95, 75.95, 110.0, 85.95, 95.95, 69.95, 75.95, 69.95, 69.95, 85.95, 49.95, 65.95, 59.95, 75.95, 69.95, 75.95, 65.95, 49.95, 49.95, 79.95, 69.95, 89.95, 119.0, 89.95, 89.95, 85.95, 69.95, 69.95, 95.95, 75.95]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
