{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\smeet\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\smeet\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\smeet\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from statistics import mean \n",
    "def getNumbers(str): \n",
    "    array = re.findall(r'[0-9]+', str)\n",
    "    return array \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = [\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=1\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=2\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=3\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=4\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=5\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=6\",\n",
    "\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=7\"\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=8\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=9\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=10\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=11\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=12\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=13\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=14\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=15\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=16\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=17\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=18\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=19\",\n",
    "#\"https://api.thesneakerdatabase.com/v1/sneakers?limit=100&page=20\"\n",
    "]\n",
    "\n",
    "database = []\n",
    "for element in database_url:\n",
    "    response = requests.get(element)\n",
    "    a = response.json()['results']\n",
    "    database.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID = []\n",
    "shoes_brand = []\n",
    "shoes_gender = []\n",
    "shoes_name = []\n",
    "shoes_year = []\n",
    "shoes_releasedate = []\n",
    "shoes_retailprice = []\n",
    "shoes_shoe = []\n",
    "categorie_shoe = []\n",
    "color = []\n",
    "img = []\n",
    "description = []\n",
    "discount_percentage = []\n",
    "\n",
    "for i in range(len(database)): \n",
    "    lijst = database[i]\n",
    "    for shoe in lijst:\n",
    "        ID = shoe['id']\n",
    "        shoes_ID.append(ID)\n",
    "        uitleg = shoe['title']\n",
    "        if uitleg == None:\n",
    "            uitleg = \"Shoe for everyone\"\n",
    "        description.append(uitleg)\n",
    "        image = shoe['media'].get('thumbUrl')\n",
    "        if image == None: \n",
    "            image = \"https://stockx.imgix.net/Nike-Air-Max-270-XX-Summit-White-Pistachio-Frost-W.png?fit=fill&bg=FFFFFF&w=140&h=100&auto=format,compress&trim=color&q=90&dpr=2&updated_at=1603481985\"\n",
    "        img.append(image)\n",
    "        brand = shoe['brand']\n",
    "        shoes_brand.append(brand)\n",
    "        gender = shoe['gender']\n",
    "        shoes_gender.append(gender)\n",
    "        name = shoe['name']\n",
    "        shoes_name.append(name)\n",
    "        year = shoe['year']\n",
    "        shoes_year.append(year)\n",
    "        releaseDate = shoe['releaseDate'].split(' ')[0]\n",
    "        shoes_releasedate.append(releaseDate)\n",
    "        retailprice = shoe['retailPrice']\n",
    "        shoes_retailprice.append((retailprice))\n",
    "        kleur = shoe['colorway']\n",
    "        color.append(kleur)\n",
    "        shoe = shoe['shoe']\n",
    "        shoes_shoe.append(shoe)\n",
    "        discount_percentage.append(0)\n",
    "\n",
    "\n",
    "lengte_db = len(database)\n",
    "lengte_lijst = len(lijst)\n",
    "x = lengte_db * lengte_lijst\n",
    "\n",
    "for a in range((x)):\n",
    "    categorie_shoe.append(\"shoe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shoes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoenen_dames = [\"https://www.torfs.be/nl/dames/schoenen/sportschoenen/?cgid=Dames-Schoenen-Sportschoenen&sz=24\",\"https://www.torfs.be/nl/dames/schoenen/wandelschoenen/?cgid=Dames-Schoenen-Wandelschoenen&sz=24\",\"https://www.torfs.be/nl/dames/schoenen/ballerinas/?cgid=Dames-Schoenen-Ballerinas&sz=24\", \"https://www.torfs.be/nl/dames/schoenen/lage-schoenen/\",\"https://www.torfs.be/nl/dames/schoenen/laarzen/?cgid=Dames-Schoenen-Laarzen&sz=24\"]\n",
    "\n",
    "prijzen_dames =[]\n",
    "product_categorie_dames = []\n",
    "brand_dames = []\n",
    "ids_dames = []\n",
    "product_name_dames = []\n",
    "product_gender_dames = []\n",
    "kleur_dames = []\n",
    "img_dames = []\n",
    "discount_percentage_dames = []\n",
    "\n",
    "for a in schoenen_dames:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "    \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__list'}):\n",
    "        for b in row.findAll('span', attrs = {'class':'value'}):\n",
    "            a = (row.text.replace('â‚¬', '').strip())\n",
    "            a = (a)\n",
    "            a = float(a.replace(\",\", \".\"))\n",
    "            prijzen_dames.append((a))\n",
    "            \n",
    "    afbeeldingen = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for x, i in enumerate(afbeeldingen):\n",
    "        a = str(afbeeldingen[x])\n",
    "        b = a.split('src=')[1]\n",
    "        b = b.split(' \" title=')[0]\n",
    "        c = b.split('; ')[0]\n",
    "        c = c.split(' ')[0]\n",
    "        c = c.rstrip('\"')\n",
    "        img_dames.append(c)\n",
    "    \n",
    "    categorie = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in categorie: \n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_dames.append(a)\n",
    "        \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_dames.append(a[len(a) - 1])\n",
    "        \n",
    "    test = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}):\n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        brand_dames.append(a)\n",
    "        \n",
    "    for x, i in enumerate(test):\n",
    "        a = str(test[x])\n",
    "        b = a.split('alt=')[1]\n",
    "        b = b.split(' \" class')[0]\n",
    "        b = b.lstrip('\" ')\n",
    "        b = b.rstrip('\" ')\n",
    "        product_name_dames.append(b)\n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_dames.append(c)\n",
    "\n",
    "            \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')\n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_percentage_dames.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_percentage_dames.append(a)\n",
    "     \n",
    "            \n",
    " \n",
    "\n",
    "            \n",
    "for x in range(len(product_name_dames) - len(kleur_dames)):\n",
    "    if len(kleur_dames) != len(product_name_dames):\n",
    "        kleur_dames.append('multi')\n",
    "for x in range(len(ids_dames)):\n",
    "    product_gender_dames.append(\"Dames\")\n",
    "        \n",
    "tekst_dames = []\n",
    "paginas_dames = []\n",
    "for x,i in enumerate(ids_dames):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/dames/schoenen/ballerinas/geox-charlene-zwarte-ballerinas-/\"+ i + \".html?\"\n",
    "    paginas_dames.append(test)\n",
    "\n",
    "for a in paginas_dames:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_dames.append(b)\n",
    "        \n",
    "average = mean(prijzen_dames)  \n",
    "average = (round(average,2))\n",
    "\n",
    "verschil = (len(product_categorie_dames) - len(prijzen_dames))\n",
    "for x in range(verschil):\n",
    "    prijzen_dames.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_dames)\n",
    "shoes_brand.extend(brand_dames)\n",
    "shoes_retailprice.extend(prijzen_dames)\n",
    "shoes_shoe.extend(product_name_dames)\n",
    "categorie_shoe.extend(product_categorie_dames)\n",
    "shoes_gender.extend(product_gender_dames)\n",
    "color.extend(kleur_dames)\n",
    "img.extend(img_dames)\n",
    "description.extend(tekst_dames)\n",
    "discount_percentage.extend(discount_percentage_dames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoenen_heren = [\"https://www.torfs.be/nl/heren/schoenen/sportschoenen/?cgid=Heren-Schoenen-Sportschoenen&sz=24\",\"https://www.torfs.be/nl/heren/schoenen/wandelschoenen/?cgid=Heren-Schoenen-Wandelschoenen&sz=24\",\"https://www.torfs.be/nl/heren/schoenen/geklede-schoenen/?cgid=Heren-Schoenen-Gekledeschoenen&sz=24\", \"https://www.torfs.be/nl/heren/schoenen/lage-schoenen/?cgid=Heren-Schoenen-Lageschoenen&sz=24\",\"https://www.torfs.be/nl/dames/schoenen/laarzen/?cgid=Dames-Schoenen-Laarzen&sz=24\"]\n",
    "\n",
    "prijzen_heren =[]\n",
    "product_categorie_heren = []\n",
    "brand_heren = []\n",
    "ids_heren = []\n",
    "product_name_heren = []\n",
    "product_gender_heren = []\n",
    "kleur_heren = []\n",
    "img_heren = []\n",
    "discount_percentage_heren = []\n",
    "\n",
    "for a in schoenen_heren:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "    \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__list'}):\n",
    "        for b in row.findAll('span', attrs = {'class':'value'}):\n",
    "            a = (row.text.replace('â‚¬', '').strip())\n",
    "            a = (a)\n",
    "            a = float(a.replace(\",\", \".\"))\n",
    "            prijzen_heren.append((a))\n",
    "            \n",
    "    afbeeldingen = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for x, i in enumerate(afbeeldingen):\n",
    "        a = str(afbeeldingen[x])\n",
    "        b = a.split('src=')[1]\n",
    "        b = b.split(' \" title=')[0]\n",
    "        c = b.split('; ')[0]\n",
    "        c = c.split(' ')[0]\n",
    "        c = c.rstrip('\"')\n",
    "        img_heren.append(c)\n",
    "    \n",
    "    categorie = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in categorie: \n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_heren.append(a)\n",
    "        \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_heren.append(a[len(a) - 1])\n",
    "        \n",
    "    test = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}):\n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        brand_heren.append(a)\n",
    "    for x, i in enumerate(test):\n",
    "        a = str(test[x])\n",
    "        b = a.split('alt=')[1]\n",
    "        b = b.split(' \" class')[0]\n",
    "        b = b.lstrip('\" ')\n",
    "        b = b.rstrip('\" ')\n",
    "        product_name_heren.append(b)\n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_heren.append(c)\n",
    "\n",
    "            \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')\n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_percentage_heren.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_percentage_heren.append(a)\n",
    "     \n",
    "            \n",
    " \n",
    "\n",
    "            \n",
    "for x in range(len(product_name_heren) - len(kleur_heren)):\n",
    "    if len(kleur_heren) != len(product_name_heren):\n",
    "        kleur_heren.append('multi')\n",
    "for x in range(len(ids_heren)):\n",
    "    product_gender_heren.append(\"Heren\")\n",
    "        \n",
    "tekst_heren = []\n",
    "paginas_heren = []\n",
    "for x,i in enumerate(ids_heren):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/heren/schoenen/geklede-schoenen/rieker-cognac-geklede-veterbottines-/\"+ i + \".html?\"\n",
    "    paginas_heren.append(test)\n",
    "for a in paginas_heren:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_heren.append(b)\n",
    "        \n",
    "average = mean(prijzen_heren)  \n",
    "average = (round(average,2))\n",
    "\n",
    "verschil = (len(product_categorie_heren) - len(prijzen_heren))\n",
    "for x in range(verschil):\n",
    "    prijzen_heren.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_heren)\n",
    "shoes_brand.extend(brand_heren)\n",
    "shoes_retailprice.extend(prijzen_heren)\n",
    "shoes_shoe.extend(product_name_heren)\n",
    "categorie_shoe.extend(product_categorie_heren)\n",
    "shoes_gender.extend(product_gender_heren)\n",
    "color.extend(kleur_heren)\n",
    "img.extend(img_heren)\n",
    "description.extend(tekst_heren)\n",
    "discount_percentage.extend(discount_percentage_heren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoenen_jongens = [\"https://www.torfs.be/nl/jongens/schoenen/sportschoenen/?cgid=Jongens-Schoenen-Sportschoenen&sz=24\",\"https://www.torfs.be/nl/jongens/schoenen/wandelschoenen/?cgid=Jongens-Schoenen-Wandelschoenen&sz=24\",\"https://www.torfs.be/nl/jongens/schoenen/lage-schoenen/?cgid=Jongens-Schoenen-Lageschoenen&sz=24/\",\"https://www.torfs.be/nl/jongens/schoenen/hoge-schoenen/?cgid=Jongens-Schoenen-Hogeschoenen&sz=24\",\"https://www.torfs.be/nl/jongens/schoenen/babyschoenen/?cgid=Jongens-Schoenen-Babyschoenen&sz=24\"]\n",
    "\n",
    "prijzen_jongens =[]\n",
    "product_categorie_jongens = []\n",
    "brand_jongens = []\n",
    "ids_jongens = []\n",
    "product_name_jongens = []\n",
    "product_gender_jongens = []\n",
    "kleur_jongens = []\n",
    "img_jongens = []\n",
    "discount_percentage_jongens = []\n",
    "\n",
    "for a in schoenen_jongens:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "    \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__list'}):\n",
    "        for b in row.findAll('span', attrs = {'class':'value'}):\n",
    "            a = (row.text.replace('â‚¬', '').strip())\n",
    "            a = (a)\n",
    "            a = float(a.replace(\",\", \".\"))\n",
    "            prijzen_jongens.append((a))\n",
    "            \n",
    "    afbeeldingen = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for x, i in enumerate(afbeeldingen):\n",
    "        a = str(afbeeldingen[x])\n",
    "        b = a.split('src=')[1]\n",
    "        b = b.split(' \" title=')[0]\n",
    "        c = b.split('; ')[0]\n",
    "        c = c.split(' ')[0]\n",
    "        c = c.rstrip('\"')\n",
    "        img_jongens.append(c)\n",
    "    \n",
    "    categorie = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in categorie: \n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_jongens.append(a)\n",
    "        \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_jongens.append(a[len(a) - 1])\n",
    "        \n",
    "    test = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "\n",
    "    for x, i in enumerate(test):\n",
    "        a = str(test[x])\n",
    "        b = a.split('alt=')[1]\n",
    "        b = b.split(' \" class')[0]\n",
    "        b = b.lstrip('\" ')\n",
    "        b = b.rstrip('\" ')\n",
    "        product_name_jongens.append(b)\n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_jongens.append(c)\n",
    "\n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}):\n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        brand_jongens.append(a)       \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')        \n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_percentage_jongens.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_percentage_jongens.append(a)\n",
    "      \n",
    " \n",
    "\n",
    "            \n",
    "for x in range(len(product_name_jongens) - len(kleur_jongens)):\n",
    "    if len(kleur_jongens) != len(product_name_jongens):\n",
    "        kleur_jongens.append('multi')\n",
    "for x in range(len(ids_jongens)):\n",
    "    product_gender_jongens.append(\"Jongens\")\n",
    "        \n",
    "tekst_jongens = []\n",
    "paginas_jongens = []\n",
    "for x,i in enumerate(ids_jongens):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/heren/schoenen/geklede-schoenen/rieker-cognac-geklede-veterbottines-/\"+ i + \".html?\"\n",
    "    paginas_jongens.append(test)\n",
    "for a in paginas_jongens:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_jongens.append(b)\n",
    "        \n",
    "        \n",
    "average = mean(prijzen_jongens)  \n",
    "average = (round(average,2))\n",
    "\n",
    "verschil = (len(product_categorie_jongens) - len(prijzen_jongens))\n",
    "for x in range(verschil):\n",
    "    prijzen_jongens.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_jongens)\n",
    "shoes_brand.extend(brand_jongens)\n",
    "shoes_retailprice.extend(prijzen_jongens)\n",
    "shoes_shoe.extend(product_name_jongens)\n",
    "categorie_shoe.extend(product_categorie_jongens)\n",
    "shoes_gender.extend(product_gender_jongens)\n",
    "color.extend(kleur_jongens)\n",
    "img.extend(img_jongens)\n",
    "description.extend(tekst_jongens)\n",
    "discount_percentage.extend(discount_percentage_jongens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoenen_meisjes = [\"https://www.torfs.be/nl/meisjes/schoenen/sportschoenen/?cgid=Meisjes-Schoenen-Sportschoenen&sz=24\",\"https://www.torfs.be/nl/meisjes/schoenen/wandelschoenen/?cgid=Meisjes-Schoenen-Wandelschoenen&sz=24\",\"https://www.torfs.be/nl/meisjes/schoenen/lage-schoenen/?cgid=Meisjes-Schoenen-Lageschoenen&sz=24\",\"https://www.torfs.be/nl/meisjes/schoenen/hoge-schoenen/?cgid=Meisjes-Schoenen-Hogeschoenen&sz=24\",\"https://www.torfs.be/nl/meisjes/schoenen/babyschoenen/?cgid=Meisjes-Schoenen-Babyschoenen&sz=24\"]\n",
    "\n",
    "prijzen_meisjes =[]\n",
    "product_categorie_meisjes = []\n",
    "brand_meisjes = []\n",
    "ids_meisjes = []\n",
    "product_name_meisjes = []\n",
    "product_gender_meisjes = []\n",
    "kleur_meisjes = []\n",
    "img_meisjes = []\n",
    "discount_percentage_meisjes = []\n",
    "\n",
    "for a in schoenen_meisjes:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") \n",
    "    \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__list'}):\n",
    "        for b in row.findAll('span', attrs = {'class':'value'}):\n",
    "            a = (row.text.replace('â‚¬', '').strip())\n",
    "            a = (a)\n",
    "            a = float(a.replace(\",\", \".\"))\n",
    "            prijzen_meisjes.append((a))\n",
    "            \n",
    "    afbeeldingen = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for x, i in enumerate(afbeeldingen):\n",
    "        a = str(afbeeldingen[x])\n",
    "        b = a.split('src=')[1]\n",
    "        b = b.split(' \" title=')[0]\n",
    "        c = b.split('; ')[0]\n",
    "        c = c.split(' ')[0]\n",
    "        c = c.rstrip('\"')\n",
    "        img_meisjes.append(c)\n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}):\n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        brand_meisjes.append(a)\n",
    "    categorie = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in categorie: \n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_meisjes.append(a)\n",
    "        \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_meisjes.append(a[len(a) - 1])\n",
    "        \n",
    "    test = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "\n",
    "    for x, i in enumerate(test):\n",
    "        a = str(test[x])\n",
    "        b = a.split('alt=')[1]\n",
    "        b = b.split(' \" class')[0]\n",
    "        b = b.lstrip('\" ')\n",
    "        b = b.rstrip('\" ')\n",
    "        product_name_meisjes.append(b)\n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_meisjes.append(c)\n",
    "\n",
    "            \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')      \n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_percentage_meisjes.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_percentage_meisjes.append(a)     \n",
    " \n",
    "\n",
    "            \n",
    "for x in range(len(product_name_meisjes) - len(kleur_meisjes)):\n",
    "    if len(kleur_meisjes) != len(product_name_meisjes):\n",
    "        kleur_meisjes.append('multi')\n",
    "for x in range(len(ids_meisjes)):\n",
    "    product_gender_meisjes.append(\"Meisjes\")\n",
    "        \n",
    "tekst_meisjes = []\n",
    "paginas_meisjes = []\n",
    "for x,i in enumerate(ids_meisjes):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/heren/schoenen/geklede-schoenen/rieker-cognac-geklede-veterbottines-/\"+ i + \".html?\"\n",
    "    paginas_meisjes.append(test)\n",
    "for a in paginas_meisjes:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_meisjes.append(b)\n",
    "        \n",
    "        \n",
    "average = mean(prijzen_meisjes)  \n",
    "average = (round(average,2))\n",
    "\n",
    "verschil = (len(product_categorie_meisjes) - len(prijzen_meisjes))\n",
    "for x in range(verschil):\n",
    "    prijzen_meisjes.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_meisjes)\n",
    "shoes_brand.extend(brand_meisjes)\n",
    "shoes_retailprice.extend(prijzen_meisjes)\n",
    "shoes_shoe.extend(product_name_meisjes)\n",
    "categorie_shoe.extend(product_categorie_meisjes)\n",
    "shoes_gender.extend(product_gender_meisjes)\n",
    "color.extend(kleur_meisjes)\n",
    "img.extend(img_meisjes)\n",
    "description.extend(tekst_meisjes)\n",
    "discount_percentage.extend(discount_percentage_meisjes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoenverzorging = [\"https://www.torfs.be/nl/dames/accessoires/schoenverzorging/?cgid=Dames-Accessoires-Schoenverzorging&sz=24\",\"https://www.torfs.be/nl/heren/accessoires/schoenverzorging/?cgid=Heren-Accessoires-Schoenverzorging&sz=24\"]\n",
    "\n",
    "prijzen_schoenverzorging=[]\n",
    "product_categorie = []\n",
    "brand = []\n",
    "ids = []\n",
    "product_name = []\n",
    "product_gender_schoenverzorging = []\n",
    "kleur = []\n",
    "img_verzorging = []\n",
    "discount_schoenverzorging = []\n",
    "\n",
    "for a in schoenverzorging:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    productDivs = soup.findAll('div', attrs={'class' : 'pdp-link brand'})\n",
    "    for div in productDivs:\n",
    "        a = (div.find('a')['href'])\n",
    "        a = a.split('nl/')[1]\n",
    "        a = a.split('/')[0]\n",
    "        product_gender_schoenverzorging.append(a)\n",
    "        \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('â‚¬','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_schoenverzorging.append(a)\n",
    "        \n",
    "    afbeeldingen = soup.find_all('img', attrs={'class' : 'tile-image'})\n",
    "    for row in afbeeldingen:\n",
    "        image = row['src']\n",
    "        img_verzorging.append(image)\n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids.append(a[len(a) - 1])\n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Schoenverzorging\":\n",
    "            brand.append(a)    \n",
    "            \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')\n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_schoenverzorging.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_schoenverzorging.append(a)\n",
    "\n",
    "    title = soup.findAll('meta',  itemprom=\"analytics\")\n",
    "    for x, i in enumerate(title):\n",
    "        strings = str(title[x])\n",
    "        woord =(strings.split('\"name\":')[1])\n",
    "        woord1 = woord.split(\",\")[0]\n",
    "        woord1 = woord1.lstrip('\" ')\n",
    "        woord1 = woord1.rstrip('\" ')\n",
    "        product_name.append(woord1)\n",
    "        \n",
    "for a in range(len(prijzen_schoenverzorging)):\n",
    "    kleur.append(\"/\")\n",
    "\n",
    "\n",
    "tekst_schoenverzorging = []\n",
    "paginas = []\n",
    "for x,i in enumerate(ids):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/dames/accessoires/schoenverzorging/famaco-eco-protect-spray-150ml-/\" + i + \".html?\"\n",
    "    paginas.append(test)\n",
    "\n",
    "for a in paginas:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_schoenverzorging.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lijsten bij elkaar voegen\n",
    "shoes_ID.extend(ids)\n",
    "shoes_brand.extend(brand)\n",
    "shoes_retailprice.extend(prijzen_schoenverzorging)\n",
    "shoes_shoe.extend(product_name)\n",
    "categorie_shoe.extend(product_categorie)\n",
    "shoes_gender.extend(product_gender_schoenverzorging)\n",
    "color.extend(kleur)\n",
    "img.extend(img_verzorging)\n",
    "description.extend(tekst_schoenverzorging)\n",
    "discount_percentage.extend(discount_schoenverzorging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "zolen = [\"https://www.torfs.be/nl/dames/accessoires/zolen/?cgid=Dames-Accessoires-Zolen&sz=24\",\"https://www.torfs.be/nl/heren/accessoires/zolen/?cgid=Heren-Accessoires-Zolen&sz=24\"]\n",
    "\n",
    "prijzen_zolen=[]\n",
    "product_categorie_zolen = []\n",
    "brand_zolen = []\n",
    "ids_zolen = []\n",
    "product_name_zolen = []\n",
    "product_gender_zolen = []\n",
    "kleur_zolen = []\n",
    "img_zolen = []\n",
    "discount_zolen = []\n",
    "for a in zolen:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    productDivs = soup.findAll('div', attrs={'class' : 'pdp-link brand'})\n",
    "    for div in productDivs:\n",
    "        a = (div.find('a')['href'])\n",
    "        a = a.split('nl/')[1]\n",
    "        a = a.split('/')[0]\n",
    "        product_gender_zolen.append(a)\n",
    "        \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('â‚¬','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_zolen.append(a)\n",
    "        \n",
    "    afbeeldingen = soup.find_all('img', attrs={'class' : 'tile-image'})\n",
    "    for row in afbeeldingen:\n",
    "        image = row['src']\n",
    "        img_zolen.append(image)       \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_zolen.append(a)\n",
    "        \n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Zolen\":\n",
    "            brand_zolen.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_zolen.append(a[len(a) - 1])\n",
    "        \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')\n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_zolen.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_zolen.append(a) \n",
    "\n",
    "    title = soup.findAll('meta',  itemprom=\"analytics\")\n",
    "    for x, i in enumerate(title):\n",
    "        strings = str(title[x])\n",
    "        woord =(strings.split('\"name\":')[1])\n",
    "        woord1 = woord.split(\",\")[0]\n",
    "        woord1 = woord1.lstrip('\" ')\n",
    "        woord1 = woord1.rstrip('\" ')\n",
    "        product_name_zolen.append(woord1)\n",
    "        \n",
    "for a in range(len(prijzen_zolen)):\n",
    "    kleur_zolen.append(\"/\")\n",
    "    \n",
    "tekst_zolen = []\n",
    "paginas = []\n",
    "for x,i in enumerate(ids_zolen):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/dames/accessoires/zolen/famaco-universal-comfort-fresh-zolen-/\" + i + \".html?\"\n",
    "    paginas.append(test)\n",
    "\n",
    "for a in paginas:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_zolen.append(b)\n",
    "        \n",
    "#tekst_zolen.append(\"Zachte katoenen inlegzool met frisse geur voor aangenaam aanvoelende blote voeten. De bovenkant uit katoen zorgt voor een uitstekende opname van het voetvocht en een aangenaam klimaat in de schoen. De tussenlaag verhindert de vorming van onaangename geurtjes. De onderkant uit zachte latex met geÃ¯ntegreerde perforaties zorgt voor een optimale verluchting.Deze zolen kunnen enkel besteld worden als je schoenen of een handtas aankoopt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_zolen)\n",
    "shoes_brand.extend(brand_zolen)\n",
    "shoes_retailprice.extend(prijzen_zolen)\n",
    "shoes_shoe.extend(product_name_zolen)\n",
    "categorie_shoe.extend(product_categorie_zolen)\n",
    "shoes_gender.extend(product_gender_zolen)\n",
    "color.extend(kleur_zolen)\n",
    "img.extend(img_zolen)\n",
    "description.extend(tekst_zolen)\n",
    "discount_percentage.extend(discount_zolen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%\n",
      "%\n"
     ]
    }
   ],
   "source": [
    "riemen = [\"https://www.torfs.be/nl/dames/accessoires/riemen/?cgid=Dames-Accessoires-Riemen&sz=24\", \"https://www.torfs.be/nl/heren/accessoires/riemen/?cgid=Heren-Accessoires-Riemen&sz=24\"]\n",
    "\n",
    "\n",
    "prijzen_riemen=[]\n",
    "product_categorie_riemen = []\n",
    "brand_riemen = []\n",
    "ids_riemen = []\n",
    "product_name_riemen = []\n",
    "product_gender_riemen = []\n",
    "kleur_riemen = []\n",
    "img_riemen = [] \n",
    "discount_riemen = []\n",
    "for a in riemen:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "    \n",
    "    afbeeldingen = soup.find_all('img', attrs={'class' : 'tile-image'})\n",
    "    for row in afbeeldingen:\n",
    "        image = row['src']\n",
    "        img_riemen.append(image) \n",
    "     \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('â‚¬','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_riemen.append((a))\n",
    "    \n",
    "    #for row in soup.findAll('span', attrs = {'class':'price__list'}):\n",
    "    #    for b in row.findAll('span', attrs = {'class':'value'}):\n",
    "    #        a = (row.text.replace('â‚¬', '').strip())\n",
    "    #        a = (a)\n",
    "    #        a = float(a.replace(\",\", \".\"))\n",
    "    #        prijzen_riemen.append((a))\n",
    "        \n",
    "    productDivs = soup.findAll('div', attrs={'class' : 'pdp-link brand'})\n",
    "    for div in productDivs:\n",
    "        a = (div.find('a')['href'])\n",
    "        a = a.split('nl/')[1]\n",
    "        a = a.split('/')[0]\n",
    "        product_gender_riemen.append(a)\n",
    "\n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_riemen.append(a)\n",
    "\n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Riem\":\n",
    "            brand_riemen.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_riemen.append(a[len(a) - 1])\n",
    "        \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')\n",
    "        print(a)\n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_riemen.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_riemen.append(a)\n",
    "\n",
    "    title = soup.findAll('meta',  itemprom=\"analytics\")\n",
    "    for x, i in enumerate(title):\n",
    "        strings = str(title[x])\n",
    "        woord =(strings.split('\"name\":')[1])\n",
    "        woord1 = woord.split(\",\")[0]\n",
    "        woord1 = woord1.lstrip('\" ')\n",
    "        woord1 = woord1.rstrip('\" ')\n",
    "        product_name_riemen.append(woord1)\n",
    "\n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_riemen.append(c)\n",
    "\n",
    "tekst_riemen = []\n",
    "paginas = []\n",
    "for x,i in enumerate(ids_riemen):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/dames/accessoires/riemen/tommy-hilfiger-zwarte-omkeerbare-riem-/\" + i + \".html?\"\n",
    "    paginas.append(test)\n",
    "\n",
    "for a in paginas:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_riemen.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_ID.extend(ids_riemen)\n",
    "shoes_brand.extend(brand_riemen)\n",
    "shoes_retailprice.extend(prijzen_riemen)\n",
    "shoes_shoe.extend(product_name_riemen)\n",
    "categorie_shoe.extend(product_categorie_riemen)\n",
    "shoes_gender.extend(product_gender_riemen)\n",
    "color.extend(kleur_riemen)\n",
    "img.extend(img_riemen)\n",
    "description.extend(tekst_riemen)\n",
    "discount_percentage.extend(discount_riemen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sokken = [\"https://www.torfs.be/nl/dames/accessoires/sokken/?cgid=Dames-Accessoires-Sokken&sz=24\", \"https://www.torfs.be/nl/heren/accessoires/sokken/?cgid=Heren-Accessoires-Sokken&sz=24\"]\n",
    "\n",
    "\n",
    "prijzen_sokken=[]\n",
    "product_categorie_sokken = []\n",
    "brand_sokken = []\n",
    "ids_sokken = []\n",
    "product_name_sokken = []\n",
    "product_gender_sokken = []\n",
    "kleur_sokken = []\n",
    "kleur_sokken_2 = []\n",
    "lijst = []\n",
    "img_sokken = []\n",
    "discount_sokken = []\n",
    "for a in sokken:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")  \n",
    "     \n",
    "        \n",
    "    for row in soup.findAll('span', attrs = {'class':'price__sales false'}): \n",
    "        a = row.span.text\n",
    "        a = a.replace('â‚¬','')\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        a = a.replace(',', '.')\n",
    "        a = float(a)\n",
    "        prijzen_sokken.append((a)) \n",
    "        \n",
    "    #for row in soup.findAll('span', attrs = {'class':'price__list'}):\n",
    "    #    for b in row.findAll('span', attrs = {'class':'value'}):\n",
    "    #        a = (row.text.replace('â‚¬', '').strip())\n",
    "    #        a = (a)\n",
    "    #        a = float(a.replace(\",\", \".\"))\n",
    "    #        prijzen_sokken.append((a))\n",
    "  \n",
    "    afbeeldingen = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "    for x, i in enumerate(afbeeldingen):\n",
    "        #print(i)\n",
    "        a = str(afbeeldingen[x])\n",
    "        b = a.split('src=')[1]\n",
    "        b = b.split(' \" title=')[0]\n",
    "        c = b.split('; ')[0]\n",
    "        c = c.split(' ')[0]\n",
    "        c = c.rstrip('\"')\n",
    "        img_sokken.append(c)\n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link brand'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        product_categorie_sokken.append(a)\n",
    "        \n",
    "        \n",
    "    for row in soup.findAll('div', attrs = {'class' : 'pdp-link'}): \n",
    "        a = row.text\n",
    "        a = a.rstrip(\"\\n\")\n",
    "        a = a.lstrip(\"\\n\")\n",
    "        if a != \"Sokken\" or a != \"Sokken\\n\":\n",
    "            brand_sokken.append(a)\n",
    "    \n",
    "    link = soup.findAll('div', attrs = {'class' : 'pdp-link brand'})\n",
    "    for row in link:\n",
    "        a = (row.find('a')['href'])\n",
    "        a = getNumbers(a)\n",
    "        ids_sokken.append(a[len(a) - 1])\n",
    "        \n",
    "    \n",
    "    test = soup.findAll('img', attrs = {'class' : 'tile-image'})\n",
    "\n",
    "    for x, i in enumerate(test):\n",
    "        a = str(test[x])\n",
    "        b = a.split('alt=')[1]\n",
    "        b = b.split(' \" class')[0]\n",
    "        b = b.lstrip('\" ')\n",
    "        b = b.rstrip('\" ')\n",
    "        product_name_sokken.append(b)\n",
    "    \n",
    "    k = soup.findAll('span', attrs = {'class' : 'color-checkbox'})\n",
    "    for x, i in enumerate(k):\n",
    "        c = (str(k[x]))\n",
    "        c = c.split(\"--\")\n",
    "        c = c[1].split(\">\")\n",
    "        c = (c[0].replace('\"' ,' '))\n",
    "        kleur_sokken.append(c)\n",
    "        \n",
    "    branding = soup.findAll('div', attrs = {'class' : 'content-asset js-seo-content'})\n",
    "\n",
    "    for row in branding:\n",
    "        a1 = row.find('h2').text\n",
    "        a1 = a1.split(' ')[2]\n",
    "        lijst.append(a1)\n",
    "    \n",
    "    discounting = soup.findAll('span', attrs = {'class' : 'discount-label discount-label--percentage discount-label--tiny discount-label--color-custom'})\n",
    "    for row in discounting:\n",
    "        a = row.text\n",
    "        a = a.replace('\\n', '')\n",
    "        a = a.replace('-', '')\n",
    "        if a == '%':\n",
    "            a = 0\n",
    "            discount_sokken.append(a)\n",
    "        else:\n",
    "            a = a.replace('%', '')\n",
    "            discount_sokken.append(a)\n",
    "        \n",
    "for x in range(aantal_sokken_vrouwen):\n",
    "    product_gender_sokken.append(lijst[0])\n",
    "for x in range(aantal_sokken_mannen):\n",
    "    product_gender_sokken.append(lijst[1])\n",
    "\n",
    "kleur_sokken_2 = kleur_sokken + kleur_sokken\n",
    "\n",
    "tekst_sokken = []\n",
    "paginas = []\n",
    "for x,i in enumerate(ids_sokken):\n",
    "    i = (str(i))\n",
    "    test = \"https://www.torfs.be/nl/dames/accessoires/sokken/puma-zwarte-sneakersokken---2-paar-/\"+ i + \".html?\"\n",
    "    paginas.append(test)\n",
    "\n",
    "for a in paginas:\n",
    "    response = requests.get(a)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    branding= soup.findAll('span', attrs = {'class' : 'attribute-siteDescription'})\n",
    "    for row in branding:\n",
    "        b = row.text\n",
    "        tekst_sokken.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "shoes_ID.extend(ids_sokken)\n",
    "shoes_brand.extend(brand_sokken)\n",
    "shoes_retailprice.extend(prijzen_sokken)\n",
    "shoes_shoe.extend(product_name_sokken)\n",
    "categorie_shoe.extend(product_categorie_sokken)\n",
    "shoes_gender.extend(product_gender_sokken)\n",
    "color.extend(kleur_sokken_2)\n",
    "img.extend(img_sokken)\n",
    "print(len(categorie))\n",
    "description.extend(tekst_sokken)\n",
    "discount_percentage.extend(discount_sokken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Some calculations to complete the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,i in enumerate(shoes_brand):\n",
    "    if i == \"Sokken\" or i == \"Enkelsokken\" or i == \" Enkelsokken\" :\n",
    "        shoes_brand.remove(i)\n",
    "\n",
    "\n",
    "for i in range(len(shoes_ID) - len(shoes_name)):\n",
    "    shoes_name.append(\"Nan\")\n",
    "for i in range(len(shoes_ID) - len(shoes_year)):\n",
    "    shoes_year.append(\"2020\")\n",
    "for i in range(len(shoes_ID) - len(shoes_releasedate)):\n",
    "    shoes_releasedate.append(\"2020-01-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "verschil = len(shoes_ID) - len(shoes_brand)\n",
    "for x in range(verschil):\n",
    "    shoes_brand.append('Schoen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n",
      "1219\n"
     ]
    }
   ],
   "source": [
    "print(len(shoes_ID))\n",
    "print(len(shoes_brand))\n",
    "print(len(shoes_gender))\n",
    "print(len(shoes_retailprice))\n",
    "print(len(shoes_shoe))\n",
    "print(len(shoes_name))\n",
    "print(len(shoes_releasedate))\n",
    "print(len(shoes_year))\n",
    "print(len(categorie_shoe))\n",
    "print(len(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        ID         Brand     Gender  \\\n",
      "0     7bc2d5fc-597f-4627-a24d-078028994dd3        adidas        men   \n",
      "1     8e17bee9-f3d5-49ea-8dcd-760f98603a78        adidas        men   \n",
      "2     ac386cd5-64a1-40f4-a233-731a4e5a8b3f          Nike        men   \n",
      "3     b2c39346-09af-419d-979c-aa62f66e1d48        adidas        men   \n",
      "4     f7761a89-57ac-46bd-a056-8047ae40efec          Nike  preschool   \n",
      "...                                    ...           ...        ...   \n",
      "1214                                270426        Levi's      heren   \n",
      "1215                                281402      Selected      heren   \n",
      "1216                                255639  Calvin Klein      heren   \n",
      "1217                                236965        Stance      heren   \n",
      "1218                                236968        Stance      heren   \n",
      "\n",
      "      Sales_Price Discount Percentage                                 Product  \\\n",
      "0          180.00                   0              adidas Ultra Boost 2.0 DNA   \n",
      "1          180.00                   0                  adidas Ultra Boost DNA   \n",
      "2          120.00                   0                          Nike Dunk High   \n",
      "3          220.00                   0              adidas Ultra Boost DNA Mid   \n",
      "4           85.00                   0                          Nike Dunk High   \n",
      "...           ...                 ...                                     ...   \n",
      "1214         7.99                   0       Levi's Witte Enkelsokken - 2 Paar   \n",
      "1215        39.99                   0  Selected Homme Zwarte Sokken â€“ 10 Paar   \n",
      "1216        15.95                   0     Calvin Klein Zwarte Sokken - 2 Paar   \n",
      "1217        19.95                   0     Stance 1972 Tour Sokken Donkergrijs   \n",
      "1218        19.95                   0              Sokken Stance Cash On Tour   \n",
      "\n",
      "                          Name  Year ReleaseDate Product_Category  \\\n",
      "0          JuJu Smith-Schuster  2020  2020-12-09             shoe   \n",
      "1                 Jalen Ramsey  2020  2020-12-09             shoe   \n",
      "2          Black Varsity Maize  2020  2020-12-09             shoe   \n",
      "3              Patrick Mahomes  2020  2020-12-09             shoe   \n",
      "4     Black Varsity Maize (PS)  2020  2020-12-09             shoe   \n",
      "...                        ...   ...         ...              ...   \n",
      "1214                       Nan  2020  2020-01-01      Enkelsokken   \n",
      "1215                       Nan  2020  2020-01-01           Sokken   \n",
      "1216                       Nan  2020  2020-01-01           Sokken   \n",
      "1217                       Nan  2020  2020-01-01           Sokken   \n",
      "1218                       Nan  2020  2020-01-01           Sokken   \n",
      "\n",
      "                                            Description  \n",
      "0        adidas Ultra Boost 2.0 DNA JuJu Smith-Schuster  \n",
      "1                   adidas Ultra Boost DNA Jalen Ramsey  \n",
      "2                          Nike Dunk High Varsity Maize  \n",
      "3            adidas Ultra Boost DNA Mid Patrick Mahomes  \n",
      "4               Nike Dunk High Black Varsity Maize (PS)  \n",
      "...                                                 ...  \n",
      "1214   Enkelsokken zijn een onmisbaar accessoire en ...  \n",
      "1215   Verwen je voeten en kies voor een leuk paar s...  \n",
      "1216   Verwen je voeten en kies voor een leuk paar s...  \n",
      "1217   Verwen je voeten en kies voor een leuk paar s...  \n",
      "1218   Verwen je voeten en kies voor een leuk paar s...  \n",
      "\n",
      "[1219 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ID': shoes_ID,\n",
    "    'Brand': shoes_brand,\n",
    "    'Gender': shoes_gender,\n",
    "    'Sales_Price': shoes_retailprice,\n",
    "    'Discount Percentage': discount_percentage,\n",
    "    'Product': shoes_shoe,\n",
    "    'Name': shoes_name,\n",
    "    'Year': shoes_year,\n",
    "    'ReleaseDate': shoes_releasedate,\n",
    "    'Product_Category' : categorie_shoe, \n",
    "    'Description' : description\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Sales_Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = [df]\n",
    "for dataset in data_cleaner:    \n",
    "    dataset['Sales_Price'].fillna(dataset['Sales_Price'].mean(), inplace = True)\n",
    "    dataset['Sales_Price'] = dataset['Sales_Price'].replace(0, mean)  \n",
    "    \n",
    "    \n",
    "df['Sales_Price'] = dataset['Sales_Price'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                     0\n",
       "Brand                  0\n",
       "Gender                 0\n",
       "Sales_Price            0\n",
       "Discount Percentage    0\n",
       "Product                0\n",
       "Name                   0\n",
       "Year                   0\n",
       "ReleaseDate            0\n",
       "Product_Category       0\n",
       "Description            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Retail_Price'] = df.apply(lambda row: row.Sales_Price - (row.Sales_Price * 0.2), axis = 1)\n",
    "df['Retail_Price'] = df['Retail_Price'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import random \n",
    "\n",
    "  \n",
    "N = 7\n",
    "lengte = len(df['ID']) \n",
    "\n",
    "review_ID = []\n",
    "\n",
    "\n",
    "for i in range(lengte):\n",
    "    res = ''.join(random.choices(string.ascii_uppercase +\n",
    "                             string.digits, k = N)) \n",
    "    review_ID.append(res)\n",
    "\n",
    "\n",
    "\n",
    "df['Review_ID'] = review_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "stock = []\n",
    "for i in range(lengte):\n",
    "    x = randint(10,150)\n",
    "    stock.append(x)\n",
    "\n",
    "\n",
    "df['Stock'] = stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = df['Gender']\n",
    "size = []\n",
    "for count,ele in enumerate(gender):\n",
    "    if ele == \"men\" or ele == \"Heren\":\n",
    "        size.insert(count, '38 - 47')\n",
    "    elif ele == \"child\" or ele == \"Jongens\" or ele == \"Meisjes\":\n",
    "        size.insert(count, '34 - 37')\n",
    "    elif ele == \"infant\" or ele == \"Jongens\" or ele == \"Meisjes\":\n",
    "        size.insert(count, '20 - 26')\n",
    "    elif ele == \"preschool\" or ele == \"Jongens\" or ele == \"Meisjes\" :\n",
    "        size.insert(count, '27 - 30')\n",
    "    elif ele == \"toddler\" or ele == \"Jongens\" or ele == \"Meisjes\":\n",
    "        size.insert(count, '31 - 34')\n",
    "    elif ele == \"women\" or ele == \"Dames\":\n",
    "        size.insert(count, '34 - 45')\n",
    "    else:\n",
    "        size.insert(count, '1 size')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Size'] = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id = []\n",
    "for x,i in enumerate((df['Product_Category'])):\n",
    "    if i == 'shoe':\n",
    "        category_id.append(\"S332167850164114\")\n",
    "    elif i == 'Schoenverzorging':  \n",
    "        category_id.append(\"S332789501641287\")\n",
    "    elif i == 'Zolen'  :\n",
    "        category_id.append(\"Z486824285647812\")\n",
    "    elif i == 'Riem'  :\n",
    "        category_id.append(\"R486154872548563\")\n",
    "    elif i == 'Sokken'  :\n",
    "        category_id.append(\"S154687234121457\") \n",
    "    elif i == 'Enkelsokken' : \n",
    "        category_id.append(\"E154548552657254\")   \n",
    "    else:\n",
    "        category_id.append(\"/\")\n",
    "df['Category_ID'] = category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = len(category_id) - len(color)\n",
    "\n",
    "if diff != 0:\n",
    "    for x in range((diff)):\n",
    "        color.append('Multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n"
     ]
    }
   ],
   "source": [
    "df['Color'] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "Popular = []\n",
    "lengte = len(df['ID'])\n",
    "print(lengte)\n",
    "for i in range(0,lengte):\n",
    "    n = random.randint(1,5)\n",
    "    Popular.append(n)\n",
    "\n",
    "df['Popular'] = Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Image_url'] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, i in enumerate(df['Sales_Price']):\n",
    "    if df['Sales_Price'][x] == 'None':\n",
    "        df['Sales_Price'][x] = 0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(discount_percentage[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_percentage_int = []\n",
    "for x, i in enumerate(discount_percentage):\n",
    "    discount_percentage_int.append((discount_percentage[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-58ba4fcf4b70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sales_Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#print(df['Sales_Price'][x])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sales_Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sales_Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sales_Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdiscounting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#print(df['Sales_Price'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "discounting = pd.Series(discount_percentage_int)\n",
    "\n",
    "for x,i in enumerate(df['Sales_Price']):\n",
    "    print(df['Sales_Price'][x])\n",
    "    df['Sales_Price'][x] = round((df['Sales_Price'][x] - ((df['Sales_Price'][x]/100) * discounting[x])))\n",
    "    \n",
    "#print(df['Sales_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for a,b in enumerate(df['Color']):\n",
    "    df['Color'][a] = df['Color'][a].replace(\"/\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for a,b in enumerate(df['Gender']):\n",
    "    df['Gender'][a] = df['Gender'][a].capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for a,b in enumerate(df['Brand']):\n",
    "    df['Brand'][a] = df['Brand'][a].capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\smeet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for a,b in enumerate(df['Product']):\n",
    "    df['Product'][a] = df['Product'][a].capitalize()\n",
    "    \n",
    "for a,b in enumerate(df['Description']):\n",
    "    df['Description'][a] = df['Description'][a].capitalize()\n",
    "        \n",
    "for a,b in enumerate(Color):\n",
    "    df['Color'][a] = df['Color'][a].capitalize()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,i in enumerate(df['Color']):\n",
    "    df['Color'] = df['Color'].str.replace(\"Rood\", \"Red\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Blauw\", \"Blue\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Geel\", \"Yellow\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Zwart\", \"Black\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Zilver\", \"Silver\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Paars\", \"Purple\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Wit\", \"White\")\n",
    "    df['Color'] = df['Color'].str.replace(\"Oranje\", \"Orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,i in enumerate(df['Gender']):\n",
    "    df['Gender'] = df['Gender'].str.replace(\"Dames\", \"Women\")\n",
    "    df['Gender'] = df['Gender'].str.replace(\"Heren\", \"Men\")\n",
    "    df['Gender'] = df['Gender'].str.replace(\"Jongens\", \"Boys\")\n",
    "    df['Gender'] = df['Gender'].str.replace(\"Meisjes\", \"Girls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('product_database.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
